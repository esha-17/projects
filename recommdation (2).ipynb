{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "nVleebQS4BTw",
        "outputId": "439dc14e-de80-407f-f341-265ce366e573"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-255a184c-fcea-4f54-8014-a6affaf4adf3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-255a184c-fcea-4f54-8014-a6affaf4adf3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYBWSY0k4h8q"
      },
      "outputs": [],
      "source": [
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58a_ZWmu6YAO"
      },
      "outputs": [],
      "source": [
        " ! kaggle datasets list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wplJMKCW6gNg",
        "outputId": "aabd46c8-0efe-4360-854e-e9a9f442dd66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/notshrirang/spotify-million-song-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading spotify-million-song-dataset.zip to /content\n",
            " 48% 10.0M/20.7M [00:00<00:00, 40.0MB/s]\n",
            "100% 20.7M/20.7M [00:00<00:00, 63.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d notshrirang/spotify-million-song-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjLkWPlR7MR6",
        "outputId": "db4c425d-1bb8-4558-8a03-2cf8813608b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  spotify-million-song-dataset.zip\n",
            "  inflating: spotify_millsongdata.csv  \n"
          ]
        }
      ],
      "source": [
        "# Unzip the downloaded file\n",
        "!unzip spotify-million-song-dataset.zip\n",
        "\n",
        "# Load the dataset into a DataFrame (replace 'filename.csv' with the actual CSV name)\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"spotify_millsongdata.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYVG1RRu-8UF",
        "outputId": "75676ff9-ca1f-43ea-d3bd-0d0b678a1ea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas scikit-learn nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzjXIbUW_hCj",
        "outputId": "7a480f99-0231-4519-ada9-37e1180bb6eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "# Download necessary NLP tools\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhF-XGz5BIKX"
      },
      "source": [
        "##LOADING AND PREPROCESSING THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LHKb_W-_lsv"
      },
      "outputs": [],
      "source": [
        "# Load the dataset (update the path to your local file)\n",
        "data = pd.read_csv('/content/spotify_millsongdata.csv')\n",
        "\n",
        "# Function to preprocess text (lowercase, remove punctuation)\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to the lyrics (text column)\n",
        "data['processed_text'] = data['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzOHeAlaBP43"
      },
      "source": [
        "##VECTORIZE THE LYRICS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwSSmwMc_u2_"
      },
      "outputs": [],
      "source": [
        "# Vectorize the text using TF-IDF\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(data['processed_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6bK68qCBXZn"
      },
      "source": [
        "##COSINE SIMILARITY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdHCJQxrAt8A"
      },
      "outputs": [],
      "source": [
        "# Reduce the dataset size for demonstration by selecting a subset of 2000 songs\n",
        "subset_data = data.sample(n=2000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Re-vectorize the text for the subset using TF-IDF\n",
        "subset_tfidf_matrix = tfidf.fit_transform(subset_data['processed_text'])\n",
        "\n",
        "# Recompute cosine similarity for the subset\n",
        "subset_cosine_sim = cosine_similarity(subset_tfidf_matrix, subset_tfidf_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzPIVld3BcNr"
      },
      "source": [
        "##RECOMMENDATION FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veLpcxKpAx2e"
      },
      "outputs": [],
      "source": [
        "# Function to recommend songs based on cosine similarity\n",
        "def recommend_songs(song_title, cosine_sim_matrix, data, num_recommendations=5):\n",
        "    # Find the index of the song in the subset dataset\n",
        "    indices = pd.Series(data.index, index=data['song']).drop_duplicates()\n",
        "\n",
        "    if song_title not in indices:\n",
        "        return f\"Song '{song_title}' not found in the dataset.\"\n",
        "\n",
        "    idx = indices[song_title]\n",
        "\n",
        "    # Get the pairwise similarity scores for the song\n",
        "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
        "\n",
        "    # Sort the songs based on similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the indices of the most similar songs (excluding the song itself)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]\n",
        "\n",
        "    # Get the song indices and titles\n",
        "    song_indices = [i[0] for i in sim_scores]\n",
        "    return data.iloc[song_indices][['artist', 'song']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM3_-lJhCz5B"
      },
      "outputs": [],
      "source": [
        "# Select a random song from the subset\n",
        "sample_song = subset_data['song'].iloc[8]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df7KLbiDC1le"
      },
      "outputs": [],
      "source": [
        "# Choose a specific song title from the subset\n",
        "sample_song = 'Dancing Queen'  # Replace with the actual title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4fZz9YsSXLM",
        "outputId": "de9cfb01-68e9-41cd-9733-d881765a61ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for 'Dancing Queen':\n"
          ]
        }
      ],
      "source": [
        "print(f\"Recommendations for '{sample_song}':\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KUQulGIBirv"
      },
      "source": [
        "##TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpivnSz7A0hf",
        "outputId": "2de89ec3-66af-47bc-acb1-e47c4f1ba17e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for 'Right Or Wrong':\n",
            "                 artist                       song\n",
            "430            Old 97's               St. Ignatius\n",
            "1973  Dusty Springfield     I've Been Wrong Before\n",
            "999          Air Supply        I Don't Believe You\n",
            "1508      Grateful Dead  Man Smart - Woman Smarter\n",
            "564      Lynyrd Skynyrd              One More Time\n"
          ]
        }
      ],
      "source": [
        "# Test the recommendation system with a sample song from the subset\n",
        "sample_song = subset_data['song'].iloc[0]\n",
        "recommendations = recommend_songs(sample_song, subset_cosine_sim, subset_data)\n",
        "\n",
        "# Display the recommendations\n",
        "print(f\"Recommendations for '{sample_song}':\")\n",
        "print(recommendations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNI-ODAWRdk9",
        "outputId": "3efcc082-4197-416f-ccb2-7661b1b1fb79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for 'Right Or Wrong':\n",
            "                 artist                            song\n",
            "430            Old 97's                    St. Ignatius\n",
            "1973  Dusty Springfield          I've Been Wrong Before\n",
            "999          Air Supply             I Don't Believe You\n",
            "1508      Grateful Dead       Man Smart - Woman Smarter\n",
            "564      Lynyrd Skynyrd                   One More Time\n",
            "866         John Legend                      Number One\n",
            "71         Indigo Girls      Pushing The Needle Too Far\n",
            "1403      Reba Mcentire  If I Had Any Sense Left At All\n",
            "1688          Bob Seger                       Which Way\n",
            "951          Zayn Malik                        It's You\n"
          ]
        }
      ],
      "source": [
        "# Test the recommendation system with a sample song from the subset and get 10 recommendations\n",
        "sample_song = subset_data['song'].iloc[0]  # Selecting the first song from the subset\n",
        "recommendations = recommend_songs(sample_song, subset_cosine_sim, subset_data, num_recommendations=10)\n",
        "\n",
        "# Display the recommendations\n",
        "print(f\"Recommendations for '{sample_song}':\")\n",
        "print(recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwnO7qXp74NF",
        "outputId": "c835a8be-6876-41fb-b5cc-4ec4aeac6244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (16.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.1)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<6,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.39.0 watchdog-5.0.3\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n"
          ]
        }
      ],
      "source": [
        "# Install streamlit and pyngrok\n",
        "!pip install streamlit\n",
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFfmAg0C7514",
        "outputId": "3ecd32cb-f2dc-4db3-9956-dc49cb392a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlit_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlit_app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "\n",
        "# Preprocess text to remove punctuation and lowercase it\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    return text\n",
        "\n",
        "# Function to get song recommendations based on cosine similarity\n",
        "def recommend_songs(song_title, cosine_sim_matrix, data, num_recommendations=5):\n",
        "    indices = pd.Series(data.index, index=data['song']).drop_duplicates()\n",
        "    if song_title not in indices:\n",
        "        return f\"Song '{song_title}' not found in the dataset.\"\n",
        "\n",
        "    idx = indices[song_title]\n",
        "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]  # Skip the first entry (itself)\n",
        "    song_indices = [i[0] for i in sim_scores]\n",
        "    return data.iloc[song_indices][['artist', 'song']]\n",
        "\n",
        "# Load the dataset\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    data = pd.read_csv(\"/content/spotify_millsongdata.csv\")  # Ensure this file is uploaded\n",
        "    data['processed_text'] = data['text'].apply(preprocess_text)  # Preprocess the text column\n",
        "    return data\n",
        "\n",
        "# Load the dataset once\n",
        "data = load_data()\n",
        "\n",
        "# Compute TF-IDF matrix\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(data['processed_text'])\n",
        "\n",
        "# Compute the cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Streamlit app interface\n",
        "st.title(\"Song Recommendation System\")\n",
        "\n",
        "# Song search input\n",
        "song_title = st.text_input(\"Enter a song title for recommendations\")\n",
        "\n",
        "if st.button(\"Get Recommendations\"):\n",
        "    if song_title:\n",
        "        recommendations = recommend_songs(song_title, cosine_sim, data)\n",
        "        st.write(f\"Recommendations for '{song_title}':\")\n",
        "        st.write(recommendations)\n",
        "    else:\n",
        "        st.write(\"Please enter a song title.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9RnMmp985AK",
        "outputId": "35b75457-c038-43f3-9d3c-891a60c148de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok config add-authtoken 2n1MfV12T8mzWcGCBoSouFrYGuc_37Yd3feX8BM1Za8XaDvTG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUqJPlwO1BaH",
        "outputId": "e000bf42-bf5e-4155-f3ad-278538553b66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_OFTCtGVT1R",
        "outputId": "9ce8726e-f648-4612-8136-723f20ab4287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ngrok\n",
            "  Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ngrok\n",
            "Successfully installed ngrok-1.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP2KqxHt9N-7",
        "outputId": "79904cad-047c-4d3f-a2d9-062a462a84fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Streamlit app is live at: NgrokTunnel: \"https://d39c-34-90-151-238.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pyngrok\n",
        "import subprocess\n",
        "\n",
        "# Run the Streamlit app in the background\n",
        "streamlit_process = subprocess.Popen(['streamlit', 'run', 'streamlit_app.py'])\n",
        "\n",
        "# Import ngrok here so it's accessible in this cell\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Create a public URL using ngrok\n",
        "public_url = ngrok.connect(8501)  # Use port 8501\n",
        "print(f\"Streamlit app is live at: {public_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2WV2vkW_znX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF90L9_r8P4x",
        "outputId": "e8fa7aad-2595-4bc7-8a8e-067e2a5a6ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pyngrok\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCdFfrARAzcG",
        "outputId": "22ea841b-2a18-4e7e-ff88-3bd8c77325bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    return text\n",
        "\n",
        "def recommend_songs(song_title, cosine_sim_matrix, data, num_recommendations=5):\n",
        "    indices = pd.Series(data.index, index=data['song']).drop_duplicates()\n",
        "    if song_title not in indices:\n",
        "        return f\"Song '{song_title}' not found in the dataset.\"\n",
        "\n",
        "    idx = indices[song_title]\n",
        "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]  # Skip the first entry (itself)\n",
        "    song_indices = [i[0] for i in sim_scores]\n",
        "    return data.iloc[song_indices][['artist', 'song']]\n",
        "\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    data = pd.read_csv(\"/content/spotify_millsongdata.csv\")\n",
        "    data['processed_text'] = data['text'].apply(preprocess_text)\n",
        "    return data\n",
        "\n",
        "data = load_data()\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(data['processed_text'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "st.title(\"Song Recommendation System\")\n",
        "song_title = st.text_input(\"Enter a song title for recommendations\")\n",
        "if st.button(\"Get Recommendations\"):\n",
        "    if song_title:\n",
        "        recommendations = recommend_songs(song_title, cosine_sim, data)\n",
        "        st.write(f\"Recommendations for '{song_title}':\")\n",
        "        st.write(recommendations)\n",
        "    else:\n",
        "        st.write(\"Please enter a song title.\")\n",
        "\n",
        "# Step 3: Start Ngrok and Streamlit\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# Stop any existing ngrok processes\n",
        "ngrok.kill()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess"
      ],
      "metadata": {
        "id": "UIoEJurzd4zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3y1g50w_1PP",
        "outputId": "703f66fb-8b95-4e43-f75e-c9c1555c3b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://ac9d-34-90-151-238.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "# Run the Streamlit app in the background\n",
        "streamlit_process = subprocess.Popen(['streamlit', 'run', 'streamlit_app.py'])\n",
        "\n",
        "# Create a public URL using ngrok\n",
        "public_url = ngrok.connect(8501)  # Use port 8501\n",
        "print(f\"Streamlit app is live at: {public_url}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zMhk7pzA4-b"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4bBf9UbL35eX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLSv4q7E1xuz",
        "outputId": "600e9074-89e6-4e45-d2fa-c3e12bd499b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-10-10 14:38:18.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:18.197 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-10-10 14:38:18.204 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:18.206 \n",
            "`st.cache` is deprecated and will be removed soon. Please use one of Streamlit's new\n",
            "caching commands, `st.cache_data` or `st.cache_resource`. More information\n",
            "[in our docs](https://docs.streamlit.io/develop/concepts/architecture/caching).\n",
            "\n",
            "**Note**: The behavior of `st.cache` was updated in Streamlit 1.36 to the new caching\n",
            "logic used by `st.cache_data` and `st.cache_resource`. This might lead to some problems\n",
            "or unexpected behavior in certain edge cases.\n",
            "\n",
            "2024-10-10 14:38:18.211 No runtime found, using MemoryCacheStorageManager\n",
            "2024-10-10 14:38:18.213 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:18.215 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:18.216 \n",
            "`st.cache` is deprecated and will be removed soon. Please use one of Streamlit's new\n",
            "caching commands, `st.cache_data` or `st.cache_resource`. More information\n",
            "[in our docs](https://docs.streamlit.io/develop/concepts/architecture/caching).\n",
            "\n",
            "**Note**: The behavior of `st.cache` was updated in Streamlit 1.36 to the new caching\n",
            "logic used by `st.cache_data` and `st.cache_resource`. This might lead to some problems\n",
            "or unexpected behavior in certain edge cases.\n",
            "\n",
            "2024-10-10 14:38:18.222 No runtime found, using MemoryCacheStorageManager\n",
            "2024-10-10 14:38:18.224 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:18.226 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:18.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:18.232 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:18.233 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:18.243 No runtime found, using MemoryCacheStorageManager\n",
            "2024-10-10 14:38:18.744 Thread 'Thread-12': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:18.750 Thread 'Thread-12': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:20.088 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:20.091 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:20.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:20.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:20.143 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:20.146 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:20.148 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:20.150 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:20.151 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Cache the dataset loading function\n",
        "@st.cache\n",
        "def load_data():\n",
        "    data = pd.read_csv('spotify_millsongdata.csv')\n",
        "    return data\n",
        "\n",
        "# Cache the TF-IDF vectorizer and cosine similarity calculations\n",
        "@st.cache\n",
        "def process_data(data):\n",
        "    tfidf = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = tfidf.fit_transform(data['processed_text'])\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "    return cosine_sim\n",
        "\n",
        "st.title('Song Recommendation System')\n",
        "\n",
        "# Load data\n",
        "data = load_data()\n",
        "\n",
        "# Display a subset of the data\n",
        "st.write(data.head(10))\n",
        "\n",
        "# Process data only when necessary (lazy loading)\n",
        "if st.button('Calculate Similarity'):\n",
        "    cosine_sim = process_data(data)\n",
        "    st.write(\"Similarity Calculated!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python streamlit_app.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kCvhv31bNor",
        "outputId": "db824825-80bf-48f5-8a38-d1d406e23670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-10 14:38:32.547 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
            "2024-10-10 14:38:32.555 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:32.755 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run streamlit_app.py [ARGUMENTS]\n",
            "2024-10-10 14:38:32.755 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:32.755 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:32.755 No runtime found, using MemoryCacheStorageManager\n",
            "2024-10-10 14:38:33.266 Thread 'Thread-1': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:33.267 Thread 'Thread-1': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:53.160 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-10 14:38:53.166 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:30+0000 lvl=warn msg=\"failed to open private leg\" id=f05056deb9b5 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:30+0000 lvl=warn msg=\"failed to open private leg\" id=44b8a414c789 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:31+0000 lvl=warn msg=\"failed to open private leg\" id=a3ce0faaf0a9 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:31+0000 lvl=warn msg=\"failed to open private leg\" id=db7bd2d77839 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:31+0000 lvl=warn msg=\"failed to open private leg\" id=dbfb497a90b1 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:31+0000 lvl=warn msg=\"failed to open private leg\" id=ff6b662046e0 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:32+0000 lvl=warn msg=\"failed to open private leg\" id=0110bf9aaa11 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:32+0000 lvl=warn msg=\"failed to open private leg\" id=83eeb9f4d208 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:33+0000 lvl=warn msg=\"failed to open private leg\" id=8c1345b67c9e privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:33+0000 lvl=warn msg=\"failed to open private leg\" id=474e66001401 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:34+0000 lvl=warn msg=\"failed to open private leg\" id=97d526afcad7 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:34+0000 lvl=warn msg=\"failed to open private leg\" id=7c1d8063ae9e privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:36+0000 lvl=warn msg=\"failed to open private leg\" id=7a0ab6b24aff privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:36+0000 lvl=warn msg=\"failed to open private leg\" id=e36590bde6de privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:37+0000 lvl=warn msg=\"failed to open private leg\" id=246c5f836c08 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:37+0000 lvl=warn msg=\"failed to open private leg\" id=77a128a238c4 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:41+0000 lvl=warn msg=\"failed to open private leg\" id=bef4367f03f5 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:41+0000 lvl=warn msg=\"failed to open private leg\" id=a0b3e7f3731a privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:42+0000 lvl=warn msg=\"failed to open private leg\" id=939e6a461427 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:42+0000 lvl=warn msg=\"failed to open private leg\" id=1a418b699ed5 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:50+0000 lvl=warn msg=\"failed to open private leg\" id=52aa30414d85 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:50+0000 lvl=warn msg=\"failed to open private leg\" id=9fb2cbfab9d1 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:51+0000 lvl=warn msg=\"failed to open private leg\" id=887ddf57e6af privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:39:51+0000 lvl=warn msg=\"failed to open private leg\" id=e7d0424eb5c7 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:40:07+0000 lvl=warn msg=\"failed to open private leg\" id=b4efdfe84584 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:40:07+0000 lvl=warn msg=\"failed to open private leg\" id=5661b4d46500 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:40:10+0000 lvl=warn msg=\"failed to open private leg\" id=02ac89c4f2df privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:40:10+0000 lvl=warn msg=\"failed to open private leg\" id=f9cdaeab9d4a privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:40:11+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-fd163774-4fba-4287-be21-aa4dd96a44a9 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:40:11+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8501-fd163774-4fba-4287-be21-aa4dd96a44a9 err=\"failed to start tunnel: session closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-10-10T14:40:11+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-1dca1ef2-6ed3-4288-8be3-e7f6cb61c692 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/streamlit_app.py\", line 33, in <module>\n",
            "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\", line 1687, in cosine_similarity\n",
            "    K = safe_sparse_dot(X_normalized, Y_normalized.T, dense_output=dense_output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py\", line 205, in safe_sparse_dot\n",
            "    ret = a @ b\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/sparse/_base.py\", line 695, in __matmul__\n",
            "    return self._matmul_dispatch(other)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/sparse/_base.py\", line 606, in _matmul_dispatch\n",
            "    return self._matmul_sparse(other)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/sparse/_compressed.py\", line 520, in _matmul_sparse\n",
            "    nnz = fn(M, N,\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxTfovoJDEs9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dac4b26-bca0-4dbe-b181-cf082e2c75d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.196.143.23:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run streamlit_app.py\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}